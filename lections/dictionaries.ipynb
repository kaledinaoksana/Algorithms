{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alg53A\n",
      "alg53B\n",
      "alg53C\n",
      "alg53D\n",
      "alg53E\n",
      "alg53F\n",
      "alg53G\n",
      "alg53H\n",
      "alg53I\n",
      "alg53J\n"
     ]
    }
   ],
   "source": [
    "import processor as proc\n",
    "\n",
    "course = 5\n",
    "module = 3\n",
    "\n",
    "tasks={\n",
    "    \"A\":\"Playlists\",\n",
    "    \"B\":\"Annagram\",\n",
    "    \"C\":\"DeleteNumbers\",\n",
    "    \"D\":\"RepeatNumber\",\n",
    "    \"E\":\"TwoOfThree\",\n",
    "    \"F\":\"ReplacingWords\",\n",
    "    \"G\":\"BuiltASquare\",\n",
    "    \"H\":\"NotAToy\",\n",
    "    \"I\":\"PlayFootball\",\n",
    "    \"J\":\"P2Prelease\"\n",
    "}\n",
    "\n",
    "for task, taskname in tasks.items():\n",
    "    tests = 5\n",
    "    problem = f\"{task}_{taskname}\"\n",
    "    name_func = f\"alg{course}{module}{task}\"\n",
    "    print(name_func)\n",
    "    input_file, output = proc.return_input_output(num_of_test=1,module=str(module), problem=problem, tests=tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Плейлисты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alg53A\n",
    "tests = 5\n",
    "task = \"A\"\n",
    "taskname = tasks[task]\n",
    "\n",
    "def create_inp(test):\n",
    "    input_file, output = proc.return_input_output(num_of_test=test,module=module, problem=f\"{task}_{taskname}\", tests=tests )\n",
    "    return input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "a c\n"
     ]
    }
   ],
   "source": [
    "# ВЕРНЫЙ ОТВЕТ\n",
    "def alg53A_output(output_file):\n",
    "    file = open(output_file, 'r') \n",
    "    n = int(file.readline().strip()) \n",
    "    arr = [str(n) for n in file.readline().strip().split(' ')]\n",
    "\n",
    "    file.close()\n",
    "    return n,arr\n",
    "\n",
    "def alg53A(input_file):\n",
    "\n",
    "    ### reading\n",
    "    file = open(input_file, 'r') \n",
    "\n",
    "    n = int(file.readline().strip()) \n",
    "    dict = {}\n",
    "    res = []\n",
    "    for i in range(n):\n",
    "        ki = int(file.readline().strip())\n",
    "        listik=[str(n) for n in file.readline().strip().split(' ')]\n",
    "        for j in range(ki):\n",
    "            song = listik[j]\n",
    "            if song not in dict:\n",
    "                dict[song]=0\n",
    "            dict[song]+=1\n",
    "            if dict[song]==n:\n",
    "                res.append(song)\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    res.sort()\n",
    "    ### code\n",
    "    print(len(res))\n",
    "    print(*res)\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "alg53A(create_inp(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def testing(fun,output_fun,module, task):\n",
    "#     for test in range(1,tests+1):\n",
    "#         taskname = tasks[task]  \n",
    "#         input_file, output = proc.return_input_output(num_of_test=test,module=module, problem=f\"{task}_{taskname}\", tests=tests )\n",
    "#         my_ans = fun(input_file)\n",
    "#         real_ans = output_fun(output)\n",
    "\n",
    "#         if my_ans==real_ans:\n",
    "#             print(\"TEST\",test,\"- true \\nans:\", my_ans ,\"\\n\")\n",
    "#         else:\n",
    "#             print(\"ERROR!!! TEST\",test,\"- false \\nmy_ans:\",my_ans, \"\\nans:\",real_ans ,\"\\n\" )\n",
    "\n",
    "# testing(alg53A,alg53A_output,module,task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Аннаграмма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alg53B\n",
    "task = \"B\"\n",
    "\n",
    "def create_inp(test):\n",
    "    input_file, output = proc.return_input_output(num_of_test=test,module=module, problem=f\"{task}_{tasks[task]}\", tests=tests )\n",
    "    return input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO\n"
     ]
    }
   ],
   "source": [
    "# Верное решение\n",
    "def is_annagram(w1,w2):\n",
    "    length = len(w1)\n",
    "    dict={}\n",
    "\n",
    "    if length!=len(w2):\n",
    "        return False\n",
    "    else:\n",
    "        for w in range(length):\n",
    "            letter = w1[w]\n",
    "            if letter not in dict:\n",
    "                dict[letter]=0\n",
    "            dict[letter]+=1\n",
    "\n",
    "        for w in range(length-1, 0-1, -1):\n",
    "            letter = w2[w]\n",
    "            if letter not in dict:\n",
    "                return False\n",
    "            else:\n",
    "                dict[letter]-=1\n",
    "                if dict[letter]==0:\n",
    "                    del dict[letter]\n",
    "                \n",
    "        if dict=={}:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "def alg53B(input_file):\n",
    "\n",
    "    file = open(input_file, 'r') \n",
    "    w1 = file.readline().strip()\n",
    "    w2 = file.readline().strip()\n",
    "    file.close()\n",
    "\n",
    "    if is_annagram(w1,w2):\n",
    "        print(\"YES\")\n",
    "    else:\n",
    "        print(\"NO\")\n",
    "    \n",
    "    pass\n",
    "\n",
    "alg53B(create_inp(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Удаление чисел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alg53С\n",
    "task = \"C\"\n",
    "\n",
    "def create_inp(test):\n",
    "    input_file, output = proc.return_input_output(num_of_test=test,module=module, problem=f\"{task}_{tasks[task]}\", tests=tests )\n",
    "    return input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Верное решение\n",
    "def alg53С(input_file):\n",
    "    \n",
    "    # input_file=\"input.txt\"\n",
    "    file = open(input_file, 'r') \n",
    "    n = int(file.readline().strip())\n",
    "    arr = list(map(int,file.readline().strip().split(\" \")))\n",
    "    file.close()\n",
    "\n",
    "    dict={}\n",
    "    for i in range(n):\n",
    "        if arr[i] not in dict:\n",
    "            dict[arr[i]]=0\n",
    "        dict[arr[i]]+=1\n",
    "\n",
    "    maximum = 0\n",
    "    for value in dict:\n",
    "        loc_maximum=dict[value]\n",
    "        if (value-1) in dict:\n",
    "            maxx_min=dict[value-1]\n",
    "            loc_maximum = max(loc_maximum,maxx_min+dict[value])\n",
    "        if (value+1) in dict:\n",
    "            maxx_plus=dict[value+1]\n",
    "            loc_maximum = max(loc_maximum,maxx_plus+dict[value])\n",
    "\n",
    "        if loc_maximum > maximum:\n",
    "            maximum = loc_maximum\n",
    "\n",
    "    print(n-maximum)\n",
    "    pass\n",
    "\n",
    "alg53С(create_inp(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Повторяющееся число"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alg53D\n",
    "task = \"D\"\n",
    "\n",
    "def create_inp(test):\n",
    "    input_file, output = proc.return_input_output(num_of_test=test,module=module, problem=f\"{task}_{tasks[task]}\", tests=tests )\n",
    "    return input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO\n"
     ]
    }
   ],
   "source": [
    "# верное решение\n",
    "def is_more(listik,k):\n",
    "    listik.sort()\n",
    "    # print(listik)\n",
    "    dict={}\n",
    "\n",
    "    length = len(listik)\n",
    "\n",
    "    for i in range(length):\n",
    "        index = listik[i]\n",
    "        if index not in dict:\n",
    "            dict[index]=True\n",
    "    \n",
    "    for index in dict:\n",
    "        for ki in range(1,k+1):\n",
    "            if index-ki in dict:\n",
    "                # print(index,ki)\n",
    "                return True\n",
    "    # print(dict)\n",
    "    return False\n",
    "    \n",
    "\n",
    "\n",
    "def alg53D(input_file):\n",
    "    \n",
    "    file = open(input_file, 'r') \n",
    "    n, k = map(int,file.readline().strip().split(\" \"))\n",
    "    arr = list(map(int,file.readline().strip().split(\" \")))\n",
    "    file.close()\n",
    "\n",
    "    dict={}\n",
    "\n",
    "    for index in range(n):\n",
    "        num = arr[index]\n",
    "        if num not in dict:\n",
    "            dict[num]=[]\n",
    "        dict[num].append(index)\n",
    "    \n",
    "    # print(dict)\n",
    "\n",
    "    for num in dict:\n",
    "        if len(dict[num])>1:\n",
    "            if is_more(dict[num],k):\n",
    "                # print(dict[num])\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "# ans = alg53D(create_inp(3))\n",
    "ans = alg53D(\"input.txt\")\n",
    "\n",
    "if ans:\n",
    "    print(\"YES\")\n",
    "else:\n",
    "    print(\"NO\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. Два из трех"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alg53E\n",
    "task = \"E\"\n",
    "\n",
    "def create_inp(test):\n",
    "    input_file, output = proc.return_input_output(num_of_test=test,module=module, problem=f\"{task}_{tasks[task]}\", tests=tests )\n",
    "    return input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 9 14 17\n"
     ]
    }
   ],
   "source": [
    "# верное решение\n",
    "def alg53E(input_file):\n",
    "    dict={}\n",
    "    file = open(input_file, 'r') \n",
    "    for iteration in range(1,4):\n",
    "        n = int(file.readline().strip())\n",
    "        arr = list(set(list(map(int,file.readline().strip().split(\" \")))))\n",
    "        for i in range(len(arr)):\n",
    "            num=arr[i]\n",
    "            if num not in dict:\n",
    "                if iteration != 3:\n",
    "                    dict[num]=1\n",
    "            else:\n",
    "                dict[num]+=1\n",
    "    file.close()\n",
    "\n",
    "    res_list=[]\n",
    "    for value in dict:\n",
    "        if dict[value]>=2:\n",
    "            res_list.append(value)\n",
    "\n",
    "    return res_list\n",
    "\n",
    "\n",
    "# ans = alg53E(create_inp(3))\n",
    "ans = alg53E(\"input.txt\")\n",
    "\n",
    "print(*sorted(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F. Замена слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alg53F\n",
    "task = \"F\"\n",
    "\n",
    "def create_inp(test):\n",
    "    input_file, output = proc.return_input_output(num_of_test=test,module=module, problem=f\"{task}_{tasks[task]}\", tests=tests )\n",
    "    return input_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: ['oubp', 'obak', 'vixk', 'peqf', 'mbxk', 'sqte', 'txxv', 'sbvg', 'araf', 'raxa', 'grbf', 'khds', 'rioc', 'riro', 'cwoa', 'dfyc', 'npoi', 'hqwj', 'uunl', 'ucsw', 'pdap', 'xckn', 'ltgz', 'eenj', 'cmar', 'ommn', 'zrru', 'vdto', 'tltl', 'qtrl', 'ivlk', 'kpot', 'lzsd', 'qlma', 'tnjf', 'xqzr', 'scqz', 'nmon', 'tujn', 'thyj', 'jwyp', 'cgvb', 'cpxu', 'konh', 'qfoy', 'voyf', 'jrnp', 'icqa', 'myai', 'mrud', 'iaop', 'myrs', 'mnec', 'cubx', 'cjjo', 'nlmt', 'fyez', 'ovjj', 'jkfa', 'hpbo', 'jmwj', 'hprp', 'shkm', 'catc', 'fnvm', 'vcbf', 'pltj', 'qwhl', 'ldio', 'ptif', 'fiem', 'ubgn', 'pgbt', 'rszc', 'nirm', 'txzs', 'orcx', 'nyjw', 'okcl', 'awkq', 'voiy', 'daae', 'iawl', 'iuvo', 'dujd', 'rqjf', 'vrar', 'vaik', 'ykna', 'ckeq', 'fohi', 'hygo', 'uhmw', 'rcqx', 'fwqk', 'qnyp', 'mfqo', 'vrwg', 'jrvu', 'fzwj', 'yemt', 'ewel', 'hmim', 'yyba', 'otwf', 'flxi', 'vxvt', 'mljg', 'fuye', 'esvs', 'rllc', 'rlpm', 'aqch', 'vvuz', 'inxa', 'xvzo', 'sjrn', 'oqnq', 'mbsn', 'iidk', 'xxhe', 'otks', 'aqnv', 'mhzs', 'sgrx', 'yvbo', 'vsao', 'abcj', 'pmyr', 'qkds', 'eqog', 'kidj', 'nfoa', 'xytq', 'zkzp', 'ghuo', 'iipl', 'fvrb', 'nvqk', 'lksf', 'jxbc', 'vvln', 'icjx', 'iuli', 'omxk', 'yuta', 'aukn', 'jicm', 'podj', 'ddbu', 'jwbc', 'uvmm', 'zymy', 'ebfm', 'djai', 'ynvo', 'ikwl', 'oybg', 'zjxr', 'ncic', 'dopg', 'acxu', 'uywf', 'halj', 'beqn', 'xqpc', 'fnfn', 'evlk', 'zhoj', 'hvgn', 'yang', 'vqdi', 'sohz', 'eigq', 'kigh', 'asux', 'jemx', 'fzim', 'zgou', 'xvjo', 'pule', 'sxwm', 'lvxw', 'bxmf', 'ithe', 'chnn', 'tncr', 'knmm', 'kvwg', 'tupf', 'tgay', 'rdpi', 'ykan', 'sgzo', 'rndw', 'layq', 'hryf', 'iljl', 'ifth', 'nrvh', 'uufz', 'jdfq', 'ovtr', 'astd', 'ejof', 'zomi', 'fvrw', 'msdb', 'yihw', 'opdc', 'nnhu', 'bpvi', 'rxzn', 'ehmb', 'rien', 'enbw', 'fzwd', 'zcxo', 'wtuy', 'dimi', 'ikjq', 'cxsj', 'ncio', 'fkiq', 'fdjj', 'okrm', 'vscd', 'sdtw', 'ardl', 'czcd', 'ibdm', 'roew', 'fkdk', 'uvup', 'iffp', 'bsqw', 'enbm', 'lhla', 'tdox', 'ztjo', 'elca', 'nnhe', 'yaoy', 'vjrp', 'fbnt', 'yely', 'zmks', 'bguj', 'uadi', 'onaf', 'qrhz', 'mdec', 'wlnv', 'khla', 'jzyc', 'mwzm', 'sgav', 'seed', 'saad', 'rfqx', 'xqsf', 'fowd', 'arkd', 'gjzs', 'albq', 'wdps', 'zddg', 'lvmp', 'mzyi', 'dlrm', 'fsli', 'wvol', 'xpzv', 'npiu', 'nhoz', 'odwo', 'mque', 'sgkx', 'nbnr', 'xmqv', 'npjh', 'xwgl', 'qnpj', 'ulwe', 'haqw', 'mwma', 'ugoq', 'ggdr', 'kezb', 'ciem', 'lvje', 'kucm', 'nzdy', 'zeyc', 'rype', 'ygkc', 'xqnq', 'qlqs', 'mvss', 'drhx', 'iywz', 'ytzv', 'jvqa', 'bfeb', 'qvcy', 'ytru', 'pwmx', 'ujgv', 'oobm', 'dyyr', 'vror', 'gvll', 'kxem', 'yeui', 'uwla', 'vvkk', 'afzb', 'lojy', 'jogf', 'jksi', 'xoan', 'zgce', 'vrue', 'ezxa', 'rhvn', 'wtjw', 'zwoz', 'qoem', 'hhas', 'lxhi', 'ellg', 'mmrd', 'twxb', 'vkca', 'iydx', 'ofmk', 'wxtc', 'tkyv', 'ohyn', 'gbnw', 'qfyu', 'qksy', 'kcoc', 'nvui'], 3: ['myt', 'egc', 'vyf', 'bze', 'erm', 'wfs', 'vez', 'vqi', 'pnw', 'arm', 'nmu', 'brf', 'qii', 'zab', 'ith', 'vks', 'lfd', 'yqc', 'rpu', 'thi', 'xay', 'hwv', 'uen', 'yjw', 'bmz', 'owm', 'qsw', 'kgz', 'qts', 'psh', 'pit', 'vvh', 'plj', 'sjo', 'mwq', 'kci', 'ggh', 'cdh', 'iuo', 'nsn', 'lce', 'hsq', 'tbi', 'ybx', 'aut', 'qnl', 'cad', 'rzk', 'rjj', 'aio', 'wfe', 'cfv', 'djg', 'vzh', 'hhn', 'syx', 'gug', 'bye', 'yrh', 'eic', 'chy', 'hoi', 'gxq', 'zad', 'ijw', 'qru', 'ahs', 'wdi', 'jhq', 'fuv', 'pwi', 'yay', 'vuh', 'siz', 'pjr', 'hte', 'eug', 'uiu', 'wtr', 'cke', 'ybp', 'avr', 'ijh', 'psk', 'tys', 'nms', 'fcw', 'bwv', 'biy', 'hqt', 'mrk', 'llg', 'qyz', 'pwf', 'lze', 'usr', 'ghj', 'luq', 'rfx', 'sln', 'agn', 'ogf', 'tsr', 'xrx', 'ccx', 'ywm', 'vdy', 'ixt', 'nya', 'hql', 'yzj', 'pju', 'fqq', 'cno', 'mez', 'vmj', 'owg', 'bdl', 'eiz', 'qfg', 'xdx', 'ihy', 'vdx', 'ngx', 'qxt', 'smv', 'lbm', 'ubn', 'blx', 'owa', 'wpb', 'pbd', 'zbg', 'dse', 'bcg', 'lom', 'rof', 'ktn', 'jba', 'han', 'hzf', 'age', 'yqw', 'sva', 'zyy', 'paw', 'sro', 'skt', 'ola', 'exa', 'xth', 'dpa', 'fls', 'gwq', 'naj', 'lou', 'zls', 'cbh', 'lrx', 'hgi', 'lyw', 'iio', 'wgl', 'xjc', 'koq', 'qep', 'xxb', 'gbj', 'keo', 'gxu', 'qdu', 'qqd', 'tmk', 'uui', 'hgm', 'pfr', 'xjb', 'mow', 'zzu', 'aqu', 'ptt', 'ysh', 'trn', 'hek', 'tld', 'trm', 'ptj', 'agy', 'jxj', 'iyp', 'lmn', 'ilp', 'qqy', 'zxm', 'qvz', 'gbu', 'umk', 'vey', 'odk', 'qnp', 'hva', 'ofs', 'les', 'pfi', 'lgt', 'tca', 'sbh', 'iwd', 'ooe', 'gyn', 'rjq', 'qqr', 'igq', 'fbg', 'bvl', 'epj', 'dnz', 'ohn', 'lic', 'fqt', 'fkr', 'oaj', 'hsy', 'ixd', 'zbu', 'dpx', 'pfh', 'jpo', 'xdz', 'voq', 'ofh', 'fjq', 'kzu', 'cnj', 'mpt', 'znd', 'bgs', 'ddv', 'zww', 'aee', 'ryz', 'fai', 'okq', 'dtr', 'xcf', 'tfq', 'hhd', 'mkz', 'gxs', 'bjv', 'bta', 'jlp', 'lcu', 'pxx', 'ifq', 'vqm', 'ggf', 'hid', 'aph', 'iaj', 'sxt', 'yho', 'jnd', 'shv', 'che', 'cus', 'qze', 'vot', 'lne', 'fpu', 'cfw', 'tqc', 'ork', 'rss', 'kaf', 'ndz', 'xuu', 'crh', 'viz', 'vqx', 'usy', 'qvx', 'vib', 'ytj', 'spl', 'qot', 'vuf', 'tic', 'vzf', 'ypa', 'hqy', 'gvh', 'zou', 'gpc', 'whn', 'rgz', 'hrq', 'trg', 'mko', 'cmt', 'ldj', 'xzd', 'yag', 'wkn', 'swx', 'xul', 'emg', 'nbw', 'tax', 'qyx', 'qcw', 'ial', 'yiv', 'qia', 'ukd', 'dnk', 'cjc', 'nbe', 'xsd', 'ubo', 'qzc', 'fnl', 'uow', 'hcf', 'xsj', 'vjr', 'gbq', 'ugt', 'qjj', 'qhh', 'aye', 'nmv', 'tvu', 'xjj', 'aez', 'ive', 'jub', 'jto', 'zok', 'tsb', 'vfu', 'eko', 'lmq', 'nvp', 'gwe', 'kng', 'gcu', 'yhm', 'hnc', 'zqj', 'nqi', 'jio', 'enp', 'pnj', 'zqp'], 2: ['ye', 'ig', 'em', 'xc', 'bx', 'qn', 'ov', 'fb', 'kb', 'cc', 'us', 'kq', 'xk', 'xz', 'nw', 'hm', 'wx', 'wd', 'pl', 'sg', 'li', 'pn', 'dr', 'tp', 'zb', 'ug', 'th', 'oq', 'cz', 'ks', 'ot', 'lk', 'qs', 'ep', 'ao', 'ci', 'po', 'pj', 'sa', 'ql', 'qc', 'xf', 'ic', 'sl', 'mr', 'yr', 'ni', 'nd', 'ec', 'ys', 'gs', 'um', 'ez', 'iz', 'nb', 'pw', 'ox', 'el', 'lh', 'hq', 'lv', 'tw', 'zn', 'ym', 'kh', 'to', 'qt', 'ls', 'rt', 'hg', 'dq', 'sk', 'ms', 'nn', 'lc', 'vm', 'zv', 'cg', 'au', 'xx', 'rw', 'qa', 'tf', 'qi', 'pb', 'ts', 'yk', 'sw', 'by', 'ap', 'ow', 'es', 'tc', 'cy', 'zz', 'it', 'hc', 'ax', 'jc', 'pp', 'hw', 'pc', 'fn', 'go', 'mj', 'sn', 'mu', 'do', 'cr', 'fs', 'sq', 'sm', 'le', 'yz', 'oc', 'wa', 'rx', 'cs', 'tl', 'sv', 'cx', 'ok', 'oy', 'xg', 'sd', 'op', 'xp', 'hz', 'jg', 'cb', 'vt', 'gn', 'ua', 'qf', 'nj', 'ka', 'za', 'my', 'hb', 'yb', 'kd', 'jf', 'jy', 'vr', 'gj', 'lq', 'ha', 'vd', 'yj', 'gi', 'ad', 'bj', 'pv', 'bn', 'fh', 'ga', 'wj', 'kk', 'ih', 'wo', 'yi', 'uc', 'ba', 'cp', 'tt', 'ix', 'iy', 'oi', 'hd', 'gv', 'ry', 'dj', 'sy', 'uf', 'hy', 'fx', 'vz', 'ja', 'bd', 'bc', 'eq', 'si', 'rj', 'fp', 'wt', 'va', 'tn', 'ro', 'ii', 'vu', 'sx', 'zo', 'zh', 'gd', 'vj', 'hu', 'cj', 'xr', 'of', 'qq', 'du', 'ma', 'sc', 'xt', 'uh', 'rm', 'lz', 'vg', 'ln', 'km', 'ux', 'ej', 'wq', 'vv', 'nk', 'zx', 'mv', 'ho', 'gh', 'fd', 'ct', 'qj', 'xm', 'rc', 'ww', 'dw', 'mk', 'bs', 'rg', 'jh', 'aw', 'oz', 'mh', 'tu', 'dn', 'te', 'ar', 'he', 'ae', 'bm', 'wb', 'fe', 'ai', 'dx', 'vk', 'fg', 'dh', 'gq', 'jl', 'be', 'yf', 'ng', 'cm', 'mt', 'an', 'xe', 'zm', 'jd', 'fq', 'qo', 'ea', 'pi', 'pu', 'lx', 'tk', 'nq', 'zc', 'ay', 'mn', 'ee', 'iv', 'ij', 'vn', 'eh', 'tz'], 1: ['q', 'z', 'x', 'o', 'e', 's', 'j', 'w', 't', 'v', 'h', 'm', 'a', 'f', 'k', 'r', 'b', 'i', 'g', 'y', 'c', 'u', 'l', 'p', 'd', 'n']}\n",
      "{3: ['myt', 'egc', 'vyf', 'bze', 'erm', 'wfs', 'vez', 'vqi', 'pnw', 'arm', 'nmu', 'brf', 'qii', 'zab', 'ith', 'vks', 'lfd', 'yqc', 'rpu', 'thi', 'xay', 'hwv', 'uen', 'yjw', 'bmz', 'owm', 'qsw', 'kgz', 'qts', 'psh', 'pit', 'vvh', 'plj', 'sjo', 'mwq', 'kci', 'ggh', 'cdh', 'iuo', 'nsn', 'lce', 'hsq', 'tbi', 'ybx', 'aut', 'qnl', 'cad', 'rzk', 'rjj', 'aio', 'wfe', 'cfv', 'djg', 'vzh', 'hhn', 'syx', 'gug', 'bye', 'yrh', 'eic', 'chy', 'hoi', 'gxq', 'zad', 'ijw', 'qru', 'ahs', 'wdi', 'jhq', 'fuv', 'pwi', 'yay', 'vuh', 'siz', 'pjr', 'hte', 'eug', 'uiu', 'wtr', 'cke', 'ybp', 'avr', 'ijh', 'psk', 'tys', 'nms', 'fcw', 'bwv', 'biy', 'hqt', 'mrk', 'llg', 'qyz', 'pwf', 'lze', 'usr', 'ghj', 'luq', 'rfx', 'sln', 'agn', 'ogf', 'tsr', 'xrx', 'ccx', 'ywm', 'vdy', 'ixt', 'nya', 'hql', 'yzj', 'pju', 'fqq', 'cno', 'mez', 'vmj', 'owg', 'bdl', 'eiz', 'qfg', 'xdx', 'ihy', 'vdx', 'ngx', 'qxt', 'smv', 'lbm', 'ubn', 'blx', 'owa', 'wpb', 'pbd', 'zbg', 'dse', 'bcg', 'lom', 'rof', 'ktn', 'jba', 'han', 'hzf', 'age', 'yqw', 'sva', 'zyy', 'paw', 'sro', 'skt', 'ola', 'exa', 'xth', 'dpa', 'fls', 'gwq', 'naj', 'lou', 'zls', 'cbh', 'lrx', 'hgi', 'lyw', 'iio', 'wgl', 'xjc', 'koq', 'qep', 'xxb', 'gbj', 'keo', 'gxu', 'qdu', 'qqd', 'tmk', 'uui', 'hgm', 'pfr', 'xjb', 'mow', 'zzu', 'aqu', 'ptt', 'ysh', 'trn', 'hek', 'tld', 'trm', 'ptj', 'agy', 'jxj', 'iyp', 'lmn', 'ilp', 'qqy', 'zxm', 'qvz', 'gbu', 'umk', 'vey', 'odk', 'qnp', 'hva', 'ofs', 'les', 'pfi', 'lgt', 'tca', 'sbh', 'iwd', 'ooe', 'gyn', 'rjq', 'qqr', 'igq', 'fbg', 'bvl', 'epj', 'dnz', 'ohn', 'lic', 'fqt', 'fkr', 'oaj', 'hsy', 'ixd', 'zbu', 'dpx', 'pfh', 'jpo', 'xdz', 'voq', 'ofh', 'fjq', 'kzu', 'cnj', 'mpt', 'znd', 'bgs', 'ddv', 'zww', 'aee', 'ryz', 'fai', 'okq', 'dtr', 'xcf', 'tfq', 'hhd', 'mkz', 'gxs', 'bjv', 'bta', 'jlp', 'lcu', 'pxx', 'ifq', 'vqm', 'ggf', 'hid', 'aph', 'iaj', 'sxt', 'yho', 'jnd', 'shv', 'che', 'cus', 'qze', 'vot', 'lne', 'fpu', 'cfw', 'tqc', 'ork', 'rss', 'kaf', 'ndz', 'xuu', 'crh', 'viz', 'vqx', 'usy', 'qvx', 'vib', 'ytj', 'spl', 'qot', 'vuf', 'tic', 'vzf', 'ypa', 'hqy', 'gvh', 'zou', 'gpc', 'whn', 'rgz', 'hrq', 'trg', 'mko', 'cmt', 'ldj', 'xzd', 'yag', 'wkn', 'swx', 'xul', 'emg', 'nbw', 'tax', 'qyx', 'qcw', 'ial', 'yiv', 'qia', 'ukd', 'dnk', 'cjc', 'nbe', 'xsd', 'ubo', 'qzc', 'fnl', 'uow', 'hcf', 'xsj', 'vjr', 'gbq', 'ugt', 'qjj', 'qhh', 'aye', 'nmv', 'tvu', 'xjj', 'aez', 'ive', 'jub', 'jto', 'zok', 'tsb', 'vfu', 'eko', 'lmq', 'nvp', 'gwe', 'kng', 'gcu', 'yhm', 'hnc', 'zqj', 'nqi', 'jio', 'enp', 'pnj', 'zqp'], 4: ['oubp', 'obak', 'vixk', 'peqf', 'mbxk', 'sqte', 'txxv', 'sbvg', 'araf', 'raxa', 'grbf', 'khds', 'rioc', 'riro', 'cwoa', 'dfyc', 'npoi', 'hqwj', 'uunl', 'ucsw', 'pdap', 'xckn', 'ltgz', 'eenj', 'cmar', 'ommn', 'zrru', 'vdto', 'tltl', 'qtrl', 'ivlk', 'kpot', 'lzsd', 'qlma', 'tnjf', 'xqzr', 'scqz', 'nmon', 'tujn', 'thyj', 'jwyp', 'cgvb', 'cpxu', 'konh', 'qfoy', 'voyf', 'jrnp', 'icqa', 'myai', 'mrud', 'iaop', 'myrs', 'mnec', 'cubx', 'cjjo', 'nlmt', 'fyez', 'ovjj', 'jkfa', 'hpbo', 'jmwj', 'hprp', 'shkm', 'catc', 'fnvm', 'vcbf', 'pltj', 'qwhl', 'ldio', 'ptif', 'fiem', 'ubgn', 'pgbt', 'rszc', 'nirm', 'txzs', 'orcx', 'nyjw', 'okcl', 'awkq', 'voiy', 'daae', 'iawl', 'iuvo', 'dujd', 'rqjf', 'vrar', 'vaik', 'ykna', 'ckeq', 'fohi', 'hygo', 'uhmw', 'rcqx', 'fwqk', 'qnyp', 'mfqo', 'vrwg', 'jrvu', 'fzwj', 'yemt', 'ewel', 'hmim', 'yyba', 'otwf', 'flxi', 'vxvt', 'mljg', 'fuye', 'esvs', 'rllc', 'rlpm', 'aqch', 'vvuz', 'inxa', 'xvzo', 'sjrn', 'oqnq', 'mbsn', 'iidk', 'xxhe', 'otks', 'aqnv', 'mhzs', 'sgrx', 'yvbo', 'vsao', 'abcj', 'pmyr', 'qkds', 'eqog', 'kidj', 'nfoa', 'xytq', 'zkzp', 'ghuo', 'iipl', 'fvrb', 'nvqk', 'lksf', 'jxbc', 'vvln', 'icjx', 'iuli', 'omxk', 'yuta', 'aukn', 'jicm', 'podj', 'ddbu', 'jwbc', 'uvmm', 'zymy', 'ebfm', 'djai', 'ynvo', 'ikwl', 'oybg', 'zjxr', 'ncic', 'dopg', 'acxu', 'uywf', 'halj', 'beqn', 'xqpc', 'fnfn', 'evlk', 'zhoj', 'hvgn', 'yang', 'vqdi', 'sohz', 'eigq', 'kigh', 'asux', 'jemx', 'fzim', 'zgou', 'xvjo', 'pule', 'sxwm', 'lvxw', 'bxmf', 'ithe', 'chnn', 'tncr', 'knmm', 'kvwg', 'tupf', 'tgay', 'rdpi', 'ykan', 'sgzo', 'rndw', 'layq', 'hryf', 'iljl', 'ifth', 'nrvh', 'uufz', 'jdfq', 'ovtr', 'astd', 'ejof', 'zomi', 'fvrw', 'msdb', 'yihw', 'opdc', 'nnhu', 'bpvi', 'rxzn', 'ehmb', 'rien', 'enbw', 'fzwd', 'zcxo', 'wtuy', 'dimi', 'ikjq', 'cxsj', 'ncio', 'fkiq', 'fdjj', 'okrm', 'vscd', 'sdtw', 'ardl', 'czcd', 'ibdm', 'roew', 'fkdk', 'uvup', 'iffp', 'bsqw', 'enbm', 'lhla', 'tdox', 'ztjo', 'elca', 'nnhe', 'yaoy', 'vjrp', 'fbnt', 'yely', 'zmks', 'bguj', 'uadi', 'onaf', 'qrhz', 'mdec', 'wlnv', 'khla', 'jzyc', 'mwzm', 'sgav', 'seed', 'saad', 'rfqx', 'xqsf', 'fowd', 'arkd', 'gjzs', 'albq', 'wdps', 'zddg', 'lvmp', 'mzyi', 'dlrm', 'fsli', 'wvol', 'xpzv', 'npiu', 'nhoz', 'odwo', 'mque', 'sgkx', 'nbnr', 'xmqv', 'npjh', 'xwgl', 'qnpj', 'ulwe', 'haqw', 'mwma', 'ugoq', 'ggdr', 'kezb', 'ciem', 'lvje', 'kucm', 'nzdy', 'zeyc', 'rype', 'ygkc', 'xqnq', 'qlqs', 'mvss', 'drhx', 'iywz', 'ytzv', 'jvqa', 'bfeb', 'qvcy', 'ytru', 'pwmx', 'ujgv', 'oobm', 'dyyr', 'vror', 'gvll', 'kxem', 'yeui', 'uwla', 'vvkk', 'afzb', 'lojy', 'jogf', 'jksi', 'xoan', 'zgce', 'vrue', 'ezxa', 'rhvn', 'wtjw', 'zwoz', 'qoem', 'hhas', 'lxhi', 'ellg', 'mmrd', 'twxb', 'vkca', 'iydx', 'ofmk', 'wxtc', 'tkyv', 'ohyn', 'gbnw', 'qfyu', 'qksy', 'kcoc', 'nvui'], 1: ['q', 'z', 'x', 'o', 'e', 's', 'j', 'w', 't', 'v', 'h', 'm', 'a', 'f', 'k', 'r', 'b', 'i', 'g', 'y', 'c', 'u', 'l', 'p', 'd', 'n'], 2: ['ye', 'ig', 'em', 'xc', 'bx', 'qn', 'ov', 'fb', 'kb', 'cc', 'us', 'kq', 'xk', 'xz', 'nw', 'hm', 'wx', 'wd', 'pl', 'sg', 'li', 'pn', 'dr', 'tp', 'zb', 'ug', 'th', 'oq', 'cz', 'ks', 'ot', 'lk', 'qs', 'ep', 'ao', 'ci', 'po', 'pj', 'sa', 'ql', 'qc', 'xf', 'ic', 'sl', 'mr', 'yr', 'ni', 'nd', 'ec', 'ys', 'gs', 'um', 'ez', 'iz', 'nb', 'pw', 'ox', 'el', 'lh', 'hq', 'lv', 'tw', 'zn', 'ym', 'kh', 'to', 'qt', 'ls', 'rt', 'hg', 'dq', 'sk', 'ms', 'nn', 'lc', 'vm', 'zv', 'cg', 'au', 'xx', 'rw', 'qa', 'tf', 'qi', 'pb', 'ts', 'yk', 'sw', 'by', 'ap', 'ow', 'es', 'tc', 'cy', 'zz', 'it', 'hc', 'ax', 'jc', 'pp', 'hw', 'pc', 'fn', 'go', 'mj', 'sn', 'mu', 'do', 'cr', 'fs', 'sq', 'sm', 'le', 'yz', 'oc', 'wa', 'rx', 'cs', 'tl', 'sv', 'cx', 'ok', 'oy', 'xg', 'sd', 'op', 'xp', 'hz', 'jg', 'cb', 'vt', 'gn', 'ua', 'qf', 'nj', 'ka', 'za', 'my', 'hb', 'yb', 'kd', 'jf', 'jy', 'vr', 'gj', 'lq', 'ha', 'vd', 'yj', 'gi', 'ad', 'bj', 'pv', 'bn', 'fh', 'ga', 'wj', 'kk', 'ih', 'wo', 'yi', 'uc', 'ba', 'cp', 'tt', 'ix', 'iy', 'oi', 'hd', 'gv', 'ry', 'dj', 'sy', 'uf', 'hy', 'fx', 'vz', 'ja', 'bd', 'bc', 'eq', 'si', 'rj', 'fp', 'wt', 'va', 'tn', 'ro', 'ii', 'vu', 'sx', 'zo', 'zh', 'gd', 'vj', 'hu', 'cj', 'xr', 'of', 'qq', 'du', 'ma', 'sc', 'xt', 'uh', 'rm', 'lz', 'vg', 'ln', 'km', 'ux', 'ej', 'wq', 'vv', 'nk', 'zx', 'mv', 'ho', 'gh', 'fd', 'ct', 'qj', 'xm', 'rc', 'ww', 'dw', 'mk', 'bs', 'rg', 'jh', 'aw', 'oz', 'mh', 'tu', 'dn', 'te', 'ar', 'he', 'ae', 'bm', 'wb', 'fe', 'ai', 'dx', 'vk', 'fg', 'dh', 'gq', 'jl', 'be', 'yf', 'ng', 'cm', 'mt', 'an', 'xe', 'zm', 'jd', 'fq', 'qo', 'ea', 'pi', 'pu', 'lx', 'tk', 'nq', 'zc', 'ay', 'mn', 'ee', 'iv', 'ij', 'vn', 'eh', 'tz']}\n",
      "f g a t x v b p o z naj e s d r i a m o q g b z v l u f s w i y j m t h p t x j i r a e c j f l c lrx c i m n m c p s w y d t o d s l l fuv d r h h t o n z f a n s o g h u m x f g h n h w o ktn p w f e n j n\n"
     ]
    }
   ],
   "source": [
    "def is_cutting(word, vocab):\n",
    "    # sorted_vocab = dict(sorted(vocab.items(), key=lambda item: item[1]))\n",
    "    for leng in vocab:\n",
    "        listik=vocab[leng]\n",
    "        for word_voc in listik:\n",
    "            if word[:leng]==word_voc:\n",
    "                return word_voc\n",
    "    return word\n",
    "\n",
    "\n",
    "def alg53F(input_file):\n",
    "\n",
    "    file = open(input_file, 'r') \n",
    "    dict_list = list(map(str,file.readline().strip().split(\" \")))\n",
    "    arr = list(map(str,file.readline().strip().split(\" \")))\n",
    "    file.close()\n",
    "\n",
    "    vocab={}\n",
    "    for i in range(len(dict_list)):\n",
    "        word=dict_list[i]\n",
    "        # word = is_cutting(word, vocab)\n",
    "        if len(word) not in vocab:\n",
    "            vocab[len(word)]=[]\n",
    "        vocab[len(word)].append(word)\n",
    "    print(vocab)\n",
    "    \n",
    "    sorted_vocab = dict(sorted(vocab.items(), key=lambda item: item[1]))\n",
    "    vocab_new={}\n",
    "    for list_word in sorted_vocab:\n",
    "        lst = sorted_vocab[list_word]\n",
    "        # print(lst)\n",
    "        for i in range(len(lst)):\n",
    "            word_new=is_cutting(lst[i], vocab)\n",
    "            if len(word_new) not in vocab_new:\n",
    "                vocab_new[len(word_new)]=[]\n",
    "            vocab_new[len(word_new)].append(word_new)\n",
    "    print(vocab_new)\n",
    "\n",
    "    res=[]\n",
    "    for word in arr:\n",
    "        res.append(is_cutting(word, vocab_new))\n",
    "\n",
    "    print(*res)\n",
    "    pass\n",
    "\n",
    "\n",
    "# alg53F(\"input.txt\")\n",
    "alg53F(create_inp(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f g a t x v b p o z n e s d r i a m o q g b z v l u f s w i y j m t h p t x j i r a e c j f l c l c i m n m c p s w y d t o d s l l f d r h h t o n z f a n s o g h u m x f g h n h w o k p w f e n j n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
